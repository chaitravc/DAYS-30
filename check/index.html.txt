<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Voice Agent - Streaming</title>
  <style>
    /* ========================= Modern Glassmorphism Background ========================= */
    body {
        margin: 0;
        font-family: 'Segoe UI', sans-serif;
        background: linear-gradient(135deg, #0b2a55, #133b73);
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        color: white;
    }

    /* ========================= Wrapper / Center Content ========================= */
    .wrapper {
        text-align: center;
        max-width: 600px;
        width: 100%;
        padding: 20px;
    }

    /* ========================= Heading ========================= */
    h1 {
        font-size: 2.5rem;
        margin-bottom: 10px;
        color: #FFD700;
        text-shadow: 0 0 15px rgba(255, 215, 0, 0.7);
    }

    /* ========================= Mic Button ========================= */
    .mic-btn {
        width: 120px;
        height: 120px;
        background: rgba(255, 215, 0, 0.15);
        border-radius: 50%;
        backdrop-filter: blur(10px);
        display: flex;
        justify-content: center;
        align-items: center;
        margin: 30px auto;
        cursor: pointer;
        transition: transform 0.2s ease, box-shadow 0.2s ease;
        box-shadow: 0 8px 20px rgba(255, 215, 0, 0.4);
        position: relative;
    }

    .mic-btn:hover {
        transform: scale(1.05);
    }

    .mic-btn.clicked {
        transform: scale(0.95);
    }

    .mic-icon {
        font-size: 2.5rem;
        transition: color 0.2s ease;
    }

    /* Recording Animation */
    .mic-btn.recording {
        animation: pulse 1.5s infinite;
        background: rgba(255, 215, 0, 0.3);
    }

    @keyframes pulse {
        0% { box-shadow: 0 0 0 0 rgba(255, 215, 0, 0.7); }
        70% { box-shadow: 0 0 0 25px rgba(255, 215, 0, 0); }
        100% { box-shadow: 0 0 0 0 rgba(255, 215, 0, 0); }
    }

    /* ========================= Status Text ========================= */
    #chat-status {
        margin: 15px 0;
        font-size: 1.1rem;
        font-weight: 500;
        color: #FFD700;
        text-shadow: 0 0 8px rgba(255, 215, 0, 0.6);
        min-height: 1.5rem;
        display: flex;
        align-items: center;
        justify-content: center;
    }

    /* Status Animation for Audio Playback */
    #chat-status[data-status="playing"] {
        animation: audioWave 2s ease-in-out infinite;
    }

    @keyframes audioWave {
        0%, 100% { color: #FFD700; }
        25% { color: #FFA500; }
        50% { color: #FF8C00; }
        75% { color: #FFA500; }
    }

    /* ========================= Transcription Output (Response Box) ========================= */
    .response-box {
        background: rgba(255, 255, 255, 0.08);
        padding: 20px;
        border-radius: 15px;
        backdrop-filter: blur(12px);
        box-shadow: 0 4px 20px rgba(255, 215, 0, 0.15);
        text-align: left;
        color: white !important;
        margin-top: 20px;
        font-size: 18px;
        max-height: 250px;
        overflow-y: auto;
        word-wrap: break-word;
        line-height: 1.6;
        scroll-behavior: smooth;
    }

    /* Custom scrollbar for response box */
    .response-box::-webkit-scrollbar {
        width: 6px;
    }

    .response-box::-webkit-scrollbar-track {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 3px;
    }

    .response-box::-webkit-scrollbar-thumb {
        background: rgba(255, 215, 0, 0.5);
        border-radius: 3px;
    }

    .response-box::-webkit-scrollbar-thumb:hover {
        background: rgba(255, 215, 0, 0.7);
    }

    /* Style individual transcripts */
    .response-box p {
        margin: 12px 0;
        padding: 10px 15px;
        border-radius: 10px;
        font-size: 16px;
        animation: fadeIn 0.4s ease-in-out;
        position: relative;
    }

    /* User message styling */
    .response-box p:not(.ai-response) {
        background: rgba(100, 149, 237, 0.15);
        border-left: 4px solid #6495ED;
        color: #E6F3FF;
    }

    /* AI response styling */
    .response-box p.ai-response {
        background: rgba(255, 215, 0, 0.15);
        border-left: 4px solid #FFD700;
        color: #FFD700 !important;
        position: relative;
    }

    /* Audio playing indicator */
    .response-box p.ai-response.playing:after {
        content: "üîä";
        position: absolute;
        right: 15px;
        top: 50%;
        transform: translateY(-50%);
        animation: audioIndicator 1s ease-in-out infinite;
    }

    @keyframes audioIndicator {
        0%, 100% { opacity: 0.5; transform: translateY(-50%) scale(1); }
        50% { opacity: 1; transform: translateY(-50%) scale(1.1); }
    }

    /* Fade-in effect for new transcripts */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }

    /* ========================= Audio Status Display ========================= */
    .audio-status {
        background: rgba(255, 255, 255, 0.08);
        padding: 18px;
        border-radius: 15px;
        backdrop-filter: blur(12px);
        margin-top: 20px;
        border: 1px solid rgba(255, 215, 0, 0.2);
        box-shadow: 0 4px 15px rgba(255, 215, 0, 0.1);
        transition: all 0.3s ease;
    }

    .audio-status:hover {
        background: rgba(255, 255, 255, 0.12);
        transform: translateY(-2px);
    }

    .audio-status p {
        margin: 10px 0;
        font-size: 14px;
        color: #FFD700;
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0;
    }

    .audio-status span {
        font-weight: bold;
        color: #ffffff;
        background: rgba(255, 215, 0, 0.2);
        padding: 4px 12px;
        border-radius: 8px;
        min-width: 70px;
        text-align: center;
        transition: all 0.2s ease;
        border: 1px solid rgba(255, 215, 0, 0.3);
    }

    /* Playback status specific styling */
    #playback-status {
        font-weight: bold;
        text-transform: uppercase;
        letter-spacing: 1px;
    }

    #playback-status[data-status="playing"] {
        background: rgba(0, 255, 0, 0.2) !important;
        color: #00FF00 !important;
        border-color: rgba(0, 255, 0, 0.5) !important;
        animation: playingGlow 2s ease-in-out infinite;
    }

    @keyframes playingGlow {
        0%, 100% { box-shadow: 0 0 5px rgba(0, 255, 0, 0.3); }
        50% { box-shadow: 0 0 15px rgba(0, 255, 0, 0.6); }
    }

    #queue-length {
        background: rgba(255, 165, 0, 0.2) !important;
        color: #FFA500 !important;
        border-color: rgba(255, 165, 0, 0.5) !important;
    }

    /* ========================= Hidden Audio Players ========================= */
    #audio-players {
        position: absolute;
        left: -9999px;
        top: -9999px;
    }

    /* ========================= Loading Indicators ========================= */
    .loading-dots {
        display: inline-block;
        position: relative;
        width: 80px;
        height: 20px;
    }

    .loading-dots div {
        position: absolute;
        top: 50%;
        width: 6px;
        height: 6px;
        border-radius: 50%;
        background: #FFD700;
        animation: loading-dots 1.2s linear infinite;
    }

    .loading-dots div:nth-child(1) { left: 8px; animation-delay: 0s; }
    .loading-dots div:nth-child(2) { left: 30px; animation-delay: -0.4s; }
    .loading-dots div:nth-child(3) { left: 52px; animation-delay: -0.8s; }

    @keyframes loading-dots {
        0%, 80%, 100% {
            transform: translateY(-50%) scale(0);
        }
        40% {
            transform: translateY(-50%) scale(1);
        }
    }

    /* ========================= Volume Control ========================= */
    .volume-control {
        background: rgba(255, 255, 255, 0.08);
        padding: 15px;
        border-radius: 10px;
        margin-top: 15px;
        display: flex;
        align-items: center;
        gap: 10px;
    }

    .volume-control label {
        color: #FFD700;
        font-size: 14px;
        min-width: 60px;
    }

    .volume-control input[type="range"] {
        flex: 1;
        height: 5px;
        background: rgba(255, 215, 0, 0.3);
        outline: none;
        border-radius: 5px;
    }

    .volume-control input[type="range"]::-webkit-slider-thumb {
        appearance: none;
        width: 15px;
        height: 15px;
        background: #FFD700;
        cursor: pointer;
        border-radius: 50%;
    }

    /* ========================= Responsive Design ========================= */
    @media (max-width: 768px) {
        .wrapper {
            max-width: 90%;
            padding: 15px;
        }

        h1 {
            font-size: 2rem;
        }

        .mic-btn {
            width: 100px;
            height: 100px;
        }

        .mic-icon {
            font-size: 2rem;
        }

        .response-box {
            max-height: 200px;
            padding: 15px;
            font-size: 16px;
        }

        .audio-status {
            padding: 15px;
        }

        .audio-status p {
            font-size: 13px;
            flex-direction: column;
            text-align: center;
            gap: 5px;
        }

        .audio-status span {
            min-width: auto;
            width: 100%;
        }
    }

    @media (max-width: 480px) {
        h1 {
            font-size: 1.8rem;
        }

        .mic-btn {
            width: 90px;
            height: 90px;
        }

        .mic-icon {
            font-size: 1.8rem;
        }

        .response-box p {
            font-size: 14px;
            padding: 8px 12px;
        }
    }
  </style>
</head>
<body>
  <div class="wrapper">
    <h1>AI Voice Agent - Streaming Audio</h1>

    <!-- Mic Button -->
    <div class="mic-btn" id="record-btn">
      <span class="mic-icon">üéôÔ∏è</span>
    </div>

    <!-- Status -->
    <p id="chat-status">Press the button to start streaming</p>

    <!-- Volume Control -->
    <div class="volume-control">
      <label for="volume-slider">Volume:</label>
      <input type="range" id="volume-slider" min="0" max="100" value="80">
      <span id="volume-value">80%</span>
    </div>

    <!-- Response / Transcript Output -->
    <div id="transcripts" class="response-box"></div>

    <!-- Audio Status Display -->
    <div id="audio-status" class="audio-status">
      <p>Audio chunks received: <span id="chunk-count">0</span></p>
      <p>Total audio data: <span id="audio-size">0</span> KB</p>
      <p>Audio queue length: <span id="queue-length">0</span></p>
      <p>Playback status: <span id="playback-status">Idle</span></p>
    </div>

    <!-- Hidden audio elements for seamless playback -->
    <div id="audio-players"></div>
  </div>

  <script>
    let ws, audioContext, source, processor;
    let audioChunks = [];
    let audioQueue = [];
    let totalChunks = 0;
    let totalAudioSize = 0;
    let isPlaying = false;
    let currentAudioIndex = 0;
    let audioPlayerPool = [];
    let maxPlayers = 8; // Reduced for better performance
    let globalVolume = 0.8;
    let currentAIResponse = null;

    const recordBtn = document.getElementById("record-btn");
    const chatStatus = document.getElementById("chat-status");
    const transcriptsDiv = document.getElementById("transcripts");
    const chunkCountSpan = document.getElementById("chunk-count");
    const audioSizeSpan = document.getElementById("audio-size");
    const queueLengthSpan = document.getElementById("queue-length");
    const playbackStatusSpan = document.getElementById("playback-status");
    const audioPlayersDiv = document.getElementById("audio-players");
    const volumeSlider = document.getElementById("volume-slider");
    const volumeValue = document.getElementById("volume-value");

    // Volume control
    volumeSlider.addEventListener('input', function() {
      globalVolume = this.value / 100;
      volumeValue.textContent = this.value + '%';

      // Apply volume to all active players
      audioPlayerPool.forEach(player => {
        if (player.inUse) {
          player.element.volume = globalVolume;
        }
      });
    });

    // Initialize audio player pool
    function initializeAudioPlayerPool() {
      audioPlayerPool = []; // Clear existing pool
      for (let i = 0; i < maxPlayers; i++) {
        const audio = document.createElement('audio');
        audio.preload = 'auto';
        audio.volume = globalVolume;
        audio.crossOrigin = 'anonymous';
        audioPlayersDiv.appendChild(audio);
        audioPlayerPool.push({
          element: audio,
          inUse: false,
          index: i,
          endHandler: null,
          errorHandler: null
        });
      }
      console.log(`üéµ Audio player pool initialized with ${maxPlayers} players`);
    }

    // Get available audio player from pool
    function getAvailablePlayer() {
      return audioPlayerPool.find(player => !player.inUse);
    }

    // Release audio player back to pool
    function releasePlayer(player) {
      if (player.endHandler) {
        player.element.removeEventListener('ended', player.endHandler);
        player.endHandler = null;
      }
      if (player.errorHandler) {
        player.element.removeEventListener('error', player.errorHandler);
        player.errorHandler = null;
      }

      player.element.pause();
      player.element.currentTime = 0;

      // Clean up blob URL
      if (player.element.src && player.element.src.startsWith('blob:')) {
        URL.revokeObjectURL(player.element.src);
      }
      player.element.src = '';
      player.inUse = false;
    }

    // Convert base64 to blob URL with optimized decoding
    function base64ToBlob(base64, mimeType = 'audio/wav') {
      try {
        const binaryString = atob(base64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }
        const blob = new Blob([bytes], { type: mimeType });
        return URL.createObjectURL(blob);
      } catch (error) {
        console.error('Error converting base64 to blob:', error);
        return null;
      }
    }

    // Queue audio chunk for playback with improved buffering
    function queueAudioChunk(base64Audio, chunkNumber) {
      try {
        const audioUrl = base64ToBlob(base64Audio);
        if (!audioUrl) {
          console.error(`Failed to create blob URL for chunk ${chunkNumber}`);
          return;
        }

        audioQueue.push({
          url: audioUrl,
          chunkNumber: chunkNumber,
          played: false,
          timestamp: Date.now()
        });

        updateQueueStatus();

        // Start playback immediately if not already playing
        if (!isPlaying && audioQueue.length > 0) {
          // Add small delay to allow for better buffering
          setTimeout(() => {
            if (!isPlaying) {
              playNextAudioChunk();
            }
          }, 50);
        }
      } catch (error) {
        console.error('Error queuing audio chunk:', error);
      }
    }

    // Enhanced playback with better error handling and smoother transitions
    async function playNextAudioChunk() {
      const nextChunk = audioQueue.find(chunk => !chunk.played);
      if (!nextChunk) {
        isPlaying = false;
        playbackStatusSpan.textContent = "Complete";
        playbackStatusSpan.removeAttribute('data-status');

        // Remove playing indicator from AI response
        if (currentAIResponse) {
          currentAIResponse.classList.remove('playing');
          const playingIndicator = document.getElementById("audio-playing-indicator");
          if (playingIndicator) {
            playingIndicator.remove();
          }

          // Add completion checkmark
          const completedIndicator = document.createElement("span");
          completedIndicator.textContent = " ‚úÖ";
          completedIndicator.style.opacity = "0.8";
          currentAIResponse.appendChild(completedIndicator);
        }
        return;
      }

      const player = getAvailablePlayer();
      if (!player) {
        console.warn('No available audio players, retrying...');
        setTimeout(() => playNextAudioChunk(), 100);
        return;
      }

      isPlaying = true;
      player.inUse = true;
      playbackStatusSpan.textContent = `Playing chunk ${nextChunk.chunkNumber}`;
      playbackStatusSpan.setAttribute('data-status', 'playing');

      // Add playing indicator to AI response
      if (currentAIResponse) {
        currentAIResponse.classList.add('playing');
      }

      // Set up event handlers with enhanced error handling
      player.endHandler = function() {
        console.log(`‚úÖ Finished playing chunk ${nextChunk.chunkNumber}`);
        nextChunk.played = true;
        releasePlayer(player);
        updateQueueStatus();

        // Continue to next chunk with minimal delay for seamless playback
        setTimeout(() => playNextAudioChunk(), 10);
      };

      player.errorHandler = function(error) {
        console.error(`‚ùå Error playing chunk ${nextChunk.chunkNumber}:`, error);
        nextChunk.played = true; // Mark as played to skip
        releasePlayer(player);
        updateQueueStatus();

        // Continue to next chunk despite error
        setTimeout(() => playNextAudioChunk(), 50);
      };

      player.element.addEventListener('ended', player.endHandler);
      player.element.addEventListener('error', player.errorHandler);

      // Enhanced loading and playback with better error handling
      try {
        player.element.src = nextChunk.url;
        player.element.volume = globalVolume;

        // Pre-load the audio
        await new Promise((resolve, reject) => {
          const timeout = setTimeout(() => reject(new Error('Load timeout')), 5000);

          player.element.addEventListener('canplaythrough', function onCanPlay() {
            clearTimeout(timeout);
            player.element.removeEventListener('canplaythrough', onCanPlay);
            resolve();
          }, { once: true });

          player.element.addEventListener('error', function onError(e) {
            clearTimeout(timeout);
            player.element.removeEventListener('error', onError);
            reject(e);
          }, { once: true });

          player.element.load();
        });

        // Play the audio
        await player.element.play();
        console.log(`üîä Playing audio chunk ${nextChunk.chunkNumber} on player ${player.index}`);

      } catch (error) {
        console.error(`Failed to load/play chunk ${nextChunk.chunkNumber}:`, error);
        player.errorHandler(error);
      }
    }

    // Update queue status display
    function updateQueueStatus() {
      const unplayedChunks = audioQueue.filter(chunk => !chunk.played).length;
      queueLengthSpan.textContent = unplayedChunks;
    }

    // Function to update audio statistics
    function updateAudioStats() {
      chunkCountSpan.textContent = audioChunks.length;
      audioSizeSpan.textContent = (totalAudioSize / 1024).toFixed(2);
    }

    // Function to estimate base64 audio size
    function estimateAudioSize(base64String) {
      return (base64String.length * 3) / 4;
    }

    // Enhanced cleanup function
    function clearAudioQueue() {
      console.log('üßπ Clearing audio queue and stopping playback...');

      // Stop all playing audio and release players
      audioPlayerPool.forEach(player => {
        if (player.inUse) {
          releasePlayer(player);
        }
      });

      // Clean up blob URLs
      audioQueue.forEach(chunk => {
        if (chunk.url && chunk.url.startsWith('blob:')) {
          URL.revokeObjectURL(chunk.url);
        }
      });

      audioQueue = [];
      audioChunks = [];
      totalAudioSize = 0;
      isPlaying = false;
      currentAIResponse = null;

      updateAudioStats();
      updateQueueStatus();
      playbackStatusSpan.textContent = "Idle";
      playbackStatusSpan.removeAttribute('data-status');
    }

    // Enhanced microphone recording with better PCM conversion
    async function startRecording() {
      try {
        clearAudioQueue();
        ws = new WebSocket("ws://localhost:8000/ws/audio");

        ws.onopen = async () => {
          chatStatus.textContent = "üé§ Listening... Speak now!";
          console.log("Connected to server");

          try {
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: {
                sampleRate: 16000,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
              }
            });

            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 16000
            });
            source = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = function(event) {
              const inputData = event.inputBuffer.getChannelData(0);

              // Enhanced PCM conversion with proper scaling
              const pcmData = new Int16Array(inputData.length);
              for (let i = 0; i < inputData.length; i++) {
                const sample = Math.max(-1, Math.min(1, inputData[i]));
                pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
              }

              if (ws.readyState === WebSocket.OPEN) {
                ws.send(pcmData.buffer);
              }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);

          } catch (micError) {
            console.error("Microphone error:", micError);
            chatStatus.textContent = "‚ùå Microphone access denied.";
          }
        };

        // Enhanced message handling
        ws.onmessage = (event) => {
          const data = JSON.parse(event.data);

          switch(data.type) {
            case "transcript":
              const userP = document.createElement("p");
              userP.textContent = `üó£Ô∏è You: ${data.text}`;
              transcriptsDiv.appendChild(userP);
              transcriptsDiv.scrollTop = transcriptsDiv.scrollHeight;
              break;

            case "llm_response_start":
              console.log("ü§ñ LLM Response started");
              chatStatus.textContent = "ü§ñ Generating response...";

              // Add AI response indicator
              currentAIResponse = document.createElement("p");
              currentAIResponse.textContent = "ü§ñ AI: ";
              currentAIResponse.className = "ai-response";
              currentAIResponse.id = "current-ai-response";
              transcriptsDiv.appendChild(currentAIResponse);
              transcriptsDiv.scrollTop = transcriptsDiv.scrollHeight;
              break;

            case "llm_text_chunk":
              // Handle streaming text from LLM
              if (currentAIResponse) {
                const currentText = currentAIResponse.textContent;
                if (currentText === "ü§ñ AI: ") {
                  currentAIResponse.textContent = "ü§ñ AI: " + data.text;
                } else {
                  currentAIResponse.textContent += data.text;
                }
                transcriptsDiv.scrollTop = transcriptsDiv.scrollHeight;
              }
              console.log("üìù LLM text chunk:", data.text);
              break;

            case "llm_response_complete":
              console.log("‚úÖ LLM text response completed");
              if (currentAIResponse) {
                // Add a visual indicator that audio is being generated
                const audioIndicator = document.createElement("span");
                audioIndicator.textContent = " üéµ";
                audioIndicator.style.opacity = "0.7";
                audioIndicator.id = "audio-generation-indicator";
                currentAIResponse.appendChild(audioIndicator);
              }
              break;

            case "audio_chunk":
              const chunkSize = estimateAudioSize(data.chunk);
              audioChunks.push(data.chunk);
              totalAudioSize += chunkSize;

              console.log(`üîä Audio chunk ${data.chunk_number} received (${(chunkSize/1024).toFixed(2)}KB)`);

              // Queue audio chunk for immediate playback
              queueAudioChunk(data.chunk, data.chunk_number);

              updateAudioStats();
              chatStatus.textContent = `üîä Streaming audio... (${audioChunks.length} chunks)`;
              chatStatus.setAttribute('data-status', 'playing');
              break;

            case "audio_complete":
              console.log("‚úÖ Audio streaming completed:", {
                totalChunks: data.total_chunks,
                receivedChunks: audioChunks.length,
                totalSize: `${(totalAudioSize / 1024).toFixed(2)} KB`
              });

              chatStatus.textContent = `‚úÖ Audio complete! Playing ${audioQueue.filter(c => !c.played).length} remaining chunks...`;
              chatStatus.removeAttribute('data-status');

              // Remove audio generation indicator and add playing indicator
              if (currentAIResponse) {
                const audioGenIndicator = document.getElementById("audio-generation-indicator");
                if (audioGenIndicator) {
                  audioGenIndicator.remove();
                }

                // Add playing indicator
                const playingIndicator = document.createElement("span");
                playingIndicator.textContent = " üîä";
                playingIndicator.id = "audio-playing-indicator";
                playingIndicator.style.animation = "audioIndicator 1s ease-in-out infinite";
                currentAIResponse.appendChild(playingIndicator);
              }
              break;

            case "session":
              console.log("üì° Session:", data.message);
              break;

            case "end_of_turn":
              console.log("üîÑ End of turn detected");
              break;

            case "termination":
              console.log("üõë Session terminated:", data.message);
              break;

            case "error":
              console.error("‚ùå Server Error:", data.message);
              chatStatus.textContent = `‚ùå Error: ${data.message}`;
              break;

            default:
              console.log("üìù Unknown message type:", data);
          }
        };

        ws.onclose = () => {
          chatStatus.textContent = "üî¥ Streaming stopped.";
          console.log("WebSocket closed");
        };

        ws.onerror = (error) => {
          console.error("WebSocket error:", error);
          chatStatus.textContent = "‚ùå Connection error.";
        };

      } catch (err) {
        console.error("Recording error:", err);
        chatStatus.textContent = "‚ùå Failed to start recording.";
      }
    }

    function stopRecording() {
      if (processor && source && audioContext) {
        processor.disconnect();
        source.disconnect();
        audioContext.close();
        chatStatus.textContent = "‚èπÔ∏è Stopping recording...";
      }
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send("EOF");
        ws.close();
      }
    }

    // Initialize the application
    document.addEventListener('DOMContentLoaded', () => {
      initializeAudioPlayerPool();
      console.log('üöÄ AI Voice Agent initialized and ready!');
    });

    // Enhanced record button with better feedback
    recordBtn.addEventListener("click", () => {
      recordBtn.classList.add("clicked");
      setTimeout(() => recordBtn.classList.remove("clicked"), 200);

      if (!recordBtn.classList.contains("recording")) {
        startRecording();
        recordBtn.classList.add("recording");
      } else {
        stopRecording();
        recordBtn.classList.remove("recording");
      }
    });

    // Enhanced cleanup on page unload
    window.addEventListener('beforeunload', () => {
      clearAudioQueue();
      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
      }
    });
  </script>
</body>
</html>
